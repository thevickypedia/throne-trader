{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71681092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installed kernelspec throne_trader_venv in /Users/vicky/Library/Jupyter/kernels/throne_trader_venv\r\n"
     ]
    }
   ],
   "source": [
    "!ipython kernel install --user --name=throne_trader_venv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1bff05a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: Configuring installation scheme with distutils config files is deprecated and will no longer work in the near future. If you are using a Homebrew or Linuxbrew Python, please see discussion at https://github.com/Homebrew/homebrew-core/issues/76621\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -qU --upgrade pip\n",
    "!pip install -qU numpy pandas tensorflow scikit-learn yfinance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57a4fd04",
   "metadata": {},
   "source": [
    "### Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25ace48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Any, List, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yfinance\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # TensorFlow to only display warning messages (level 2) and higher\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "22bd78e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALER = MinMaxScaler(feature_range=(0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92b72d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historical_data(symbol: str,\n",
    "                        years: int = 1) -> Union[List[Tuple[str, float]], pd.DataFrame]:\n",
    "    print(f\"Downloading stock data for {symbol} for {years} years.\")\n",
    "    start = (datetime.now() - timedelta(days=years * 365)).strftime(\"%Y-%m-%d\")\n",
    "    end = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "    stock_data = yfinance.download(symbol, start=start, end=end)\n",
    "    return stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43f32858",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(data: pd.DataFrame,\n",
    "                 look_back: int = 7) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    scaled_data = SCALER.fit_transform(data['Close'].values.reshape(-1, 1))\n",
    "\n",
    "    x_axis, y_axis = [], []\n",
    "    for i in range(len(scaled_data) - look_back):\n",
    "        x_axis.append(scaled_data[i:i + look_back])\n",
    "        y_axis.append(scaled_data[i + look_back])\n",
    "\n",
    "    x_axis, y_axis = np.array(x_axis), np.array(y_axis)\n",
    "    x_axis = np.reshape(x_axis, (x_axis.shape[0], x_axis.shape[1], 1))\n",
    "\n",
    "    return x_axis, y_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "320ac524",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_model(input_shape: Tuple[Any, int]) -> Sequential:\n",
    "    sequential = Sequential()\n",
    "    sequential.add(LSTM(units=50, return_sequences=True, input_shape=input_shape))\n",
    "    sequential.add(LSTM(units=50))\n",
    "    sequential.add(Dense(1))\n",
    "    sequential.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    return sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c50e7f68",
   "metadata": {},
   "source": [
    "### Set ticker, epoch size and batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea5b8c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "TICKER = \"GOOGL\"\n",
    "EPOCH_SIZE = 100\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973b4819",
   "metadata": {},
   "source": [
    "### Download training and validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "efa24ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading stock data for GOOGL for 5 years.\n",
      "[*********************100%***********************]  1 of 1 completed\n",
      "Downloading stock data for GOOGL for 1 years.\n",
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    }
   ],
   "source": [
    "training_dataset = get_historical_data(symbol=TICKER, years=5)\n",
    "validation_dataset = get_historical_data(symbol=TICKER, years=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8018d181",
   "metadata": {},
   "source": [
    "### Prepare the data, build and train the LSTM model using the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14188b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "40/40 [==============================] - 3s 5ms/step - loss: 0.0480\n",
      "Epoch 2/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0017\n",
      "Epoch 3/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0012\n",
      "Epoch 4/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 5/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 6/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 7/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 8/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 9/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 10/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 11/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 12/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 13/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0011\n",
      "Epoch 14/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0010\n",
      "Epoch 15/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0012\n",
      "Epoch 16/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 17/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 18/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 19/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0010\n",
      "Epoch 20/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0010\n",
      "Epoch 21/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0010\n",
      "Epoch 22/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0010\n",
      "Epoch 23/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 24/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0010\n",
      "Epoch 25/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 9.9339e-04\n",
      "Epoch 26/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0010\n",
      "Epoch 27/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 28/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 9.3694e-04\n",
      "Epoch 29/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 9.7431e-04\n",
      "Epoch 30/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 9.2942e-04\n",
      "Epoch 31/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 9.4242e-04\n",
      "Epoch 32/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 9.6745e-04\n",
      "Epoch 33/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 0.0011\n",
      "Epoch 34/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 9.1136e-04\n",
      "Epoch 35/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 0.0012\n",
      "Epoch 36/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 9.7003e-04\n",
      "Epoch 37/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 8.6760e-04\n",
      "Epoch 38/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 9.2890e-04\n",
      "Epoch 39/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 8.8058e-04\n",
      "Epoch 40/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 9.2450e-04\n",
      "Epoch 41/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 8.5970e-04\n",
      "Epoch 42/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 8.3647e-04\n",
      "Epoch 43/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 8.6147e-04\n",
      "Epoch 44/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 8.2649e-04\n",
      "Epoch 45/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 7.8814e-04\n",
      "Epoch 46/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 7.7016e-04\n",
      "Epoch 47/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 7.8684e-04\n",
      "Epoch 48/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 7.7567e-04\n",
      "Epoch 49/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 8.7839e-04\n",
      "Epoch 50/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 7.4889e-04\n",
      "Epoch 51/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 7.9638e-04\n",
      "Epoch 52/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 7.3354e-04\n",
      "Epoch 53/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 7.4058e-04\n",
      "Epoch 54/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 8.5524e-04\n",
      "Epoch 55/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 7.1900e-04\n",
      "Epoch 56/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.6288e-04\n",
      "Epoch 57/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 8.0255e-04\n",
      "Epoch 58/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.5206e-04\n",
      "Epoch 59/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.9853e-04\n",
      "Epoch 60/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.2633e-04\n",
      "Epoch 61/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 8.2761e-04\n",
      "Epoch 62/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 7.4244e-04\n",
      "Epoch 63/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 9.8152e-04\n",
      "Epoch 64/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.4397e-04\n",
      "Epoch 65/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.0240e-04\n",
      "Epoch 66/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 5.7248e-04\n",
      "Epoch 67/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.8868e-04\n",
      "Epoch 68/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.0603e-04\n",
      "Epoch 69/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 6.8496e-04\n",
      "Epoch 70/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.6907e-04\n",
      "Epoch 71/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.2967e-04\n",
      "Epoch 72/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 5.4652e-04\n",
      "Epoch 73/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 5.3908e-04\n",
      "Epoch 74/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 6.1279e-04\n",
      "Epoch 75/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.7246e-04\n",
      "Epoch 76/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.9332e-04\n",
      "Epoch 77/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.1630e-04\n",
      "Epoch 78/100\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 4.8620e-04\n",
      "Epoch 79/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.1888e-04\n",
      "Epoch 80/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.0605e-04\n",
      "Epoch 81/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.8843e-04\n",
      "Epoch 82/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.8646e-04\n",
      "Epoch 83/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.5640e-04\n",
      "Epoch 84/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.2145e-04\n",
      "Epoch 85/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.5669e-04\n",
      "Epoch 86/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.6794e-04\n",
      "Epoch 87/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.4641e-04\n",
      "Epoch 88/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.6379e-04\n",
      "Epoch 89/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.7117e-04\n",
      "Epoch 90/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.2672e-04\n",
      "Epoch 91/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.3102e-04\n",
      "Epoch 92/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.3802e-04\n",
      "Epoch 93/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 5.4524e-04\n",
      "Epoch 94/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.5875e-04\n",
      "Epoch 95/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.3504e-04\n",
      "Epoch 96/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.2496e-04\n",
      "Epoch 97/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.2278e-04\n",
      "Epoch 98/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/40 [==============================] - 0s 4ms/step - loss: 4.2014e-04\n",
      "Epoch 99/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.5455e-04\n",
      "Epoch 100/100\n",
      "40/40 [==============================] - 0s 4ms/step - loss: 4.2563e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1505fdc10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare the data\n",
    "x, y = prepare_data(data=training_dataset)\n",
    "\n",
    "# Build the LSTM model\n",
    "model = build_lstm_model(input_shape=(x.shape[1], 1))\n",
    "\n",
    "# Train the model on the entire historical dataset\n",
    "model.fit(x, y, epochs=EPOCH_SIZE, batch_size=BATCH_SIZE, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c7870e",
   "metadata": {},
   "source": [
    "### Use the trained model to predict future stock prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d57cce10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model's predictive capability in a realistic scenario where it encounters new, unseen data\n",
    "future_x, _ = prepare_data(validation_dataset)\n",
    "\n",
    "# Make predictions for the future period\n",
    "future_predictions = model.predict(future_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1439b4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse transform the predictions to get the actual stock prices.\n",
    "SCALER.fit(training_dataset['Close'].values.reshape(-1, 1))\n",
    "transformed_future_predictions = SCALER.inverse_transform(future_predictions)\n",
    "\n",
    "# Extract future dates for the validation period\n",
    "future_dates = pd.date_range(start=training_dataset.index[-1],\n",
    "                             periods=len(transformed_future_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57d8a365",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2023-08-10    119.865799\n",
       "2023-08-11    114.188652\n",
       "2023-08-12    112.493149\n",
       "2023-08-13    111.975479\n",
       "2023-08-14    116.486595\n",
       "2023-08-15    107.934662\n",
       "2023-08-16    104.072311\n",
       "2023-08-17    102.456261\n",
       "2023-08-18    101.120712\n",
       "2023-08-19    102.880402\n",
       "2023-08-20    100.901505\n",
       "2023-08-21     98.584206\n",
       "2023-08-22    101.430717\n",
       "2023-08-23    101.181671\n",
       "2023-08-24    104.103477\n",
       "2023-08-25    105.498512\n",
       "2023-08-26     96.677589\n",
       "2023-08-27     94.440811\n",
       "2023-08-28     91.269310\n",
       "2023-08-29     89.987389\n",
       "2023-08-30     89.955780\n",
       "2023-08-31     87.594437\n",
       "2023-09-01     84.246201\n",
       "2023-09-02     83.821068\n",
       "2023-09-03     82.207100\n",
       "2023-09-04     80.799057\n",
       "2023-09-05     79.422462\n",
       "2023-09-06     81.603630\n",
       "2023-09-07     79.998138\n",
       "2023-09-08     77.038101\n",
       "2023-09-09     78.715767\n",
       "2023-09-10     83.295135\n",
       "2023-09-11     85.552490\n",
       "2023-09-12     86.322388\n",
       "2023-09-13     83.271507\n",
       "2023-09-14     80.738976\n",
       "2023-09-15     78.932129\n",
       "2023-09-16     78.606575\n",
       "2023-09-17     80.217697\n",
       "2023-09-18     78.402702\n",
       "2023-09-19     80.958969\n",
       "2023-09-20     83.478104\n",
       "2023-09-21     83.354630\n",
       "2023-09-22     83.440781\n",
       "2023-09-23     84.814827\n",
       "2023-09-24     87.163925\n",
       "2023-09-25     90.682594\n",
       "2023-09-26     80.846901\n",
       "2023-09-27     73.098808\n",
       "2023-09-28     73.875076\n",
       "2023-09-29     73.158257\n",
       "2023-09-30     68.684074\n",
       "2023-10-01     62.792664\n",
       "2023-10-02     56.448105\n",
       "2023-10-03     55.352226\n",
       "2023-10-04     56.938770\n",
       "2023-10-05     58.670704\n",
       "2023-10-06     58.434341\n",
       "2023-10-07     63.599705\n",
       "2023-10-08     69.965637\n",
       "2023-10-09     73.150024\n",
       "2023-10-10     77.104836\n",
       "2023-10-11     79.635025\n",
       "2023-10-12     80.169037\n",
       "2023-10-13     79.225555\n",
       "2023-10-14     76.657211\n",
       "2023-10-15     76.842926\n",
       "2023-10-16     78.729996\n",
       "2023-10-17     78.730598\n",
       "2023-10-18     77.027138\n",
       "2023-10-19     75.132607\n",
       "2023-10-20     80.361038\n",
       "2023-10-21     83.749184\n",
       "2023-10-22     84.518028\n",
       "2023-10-23     83.454857\n",
       "2023-10-24     79.990044\n",
       "2023-10-25     76.065849\n",
       "2023-10-26     72.973183\n",
       "2023-10-27     70.637573\n",
       "2023-10-28     70.002167\n",
       "2023-10-29     72.129463\n",
       "2023-10-30     72.993889\n",
       "2023-10-31     69.137245\n",
       "2023-11-01     66.098549\n",
       "2023-11-02     62.882977\n",
       "2023-11-03     61.634380\n",
       "2023-11-04     61.659515\n",
       "2023-11-05     60.254639\n",
       "2023-11-06     60.491909\n",
       "2023-11-07     59.306347\n",
       "2023-11-08     57.278820\n",
       "2023-11-09     57.941959\n",
       "2023-11-10     58.570160\n",
       "2023-11-11     59.701519\n",
       "2023-11-12     59.589180\n",
       "2023-11-13     57.745277\n",
       "2023-11-14     57.330093\n",
       "2023-11-15     57.863403\n",
       "2023-11-16     58.669075\n",
       "2023-11-17     61.843155\n",
       "2023-11-18     63.780216\n",
       "2023-11-19     65.604019\n",
       "2023-11-20     65.858887\n",
       "2023-11-21     65.613136\n",
       "2023-11-22     67.190254\n",
       "2023-11-23     73.147560\n",
       "2023-11-24     78.890251\n",
       "2023-11-25     79.546364\n",
       "2023-11-26     76.576408\n",
       "2023-11-27     77.212425\n",
       "2023-11-28     79.911835\n",
       "2023-11-29     78.819984\n",
       "2023-11-30     79.999352\n",
       "2023-12-01     82.488014\n",
       "2023-12-02     92.370270\n",
       "2023-12-03     93.915840\n",
       "2023-12-04     91.373901\n",
       "2023-12-05     95.989075\n",
       "2023-12-06     87.824959\n",
       "2023-12-07     79.022751\n",
       "2023-12-08     74.931305\n",
       "2023-12-09     73.347656\n",
       "2023-12-10     72.891235\n",
       "2023-12-11     75.102722\n",
       "2023-12-12     74.902481\n",
       "2023-12-13     73.408760\n",
       "2023-12-14     69.963112\n",
       "2023-12-15     67.887772\n",
       "2023-12-16     66.219406\n",
       "2023-12-17     63.771870\n",
       "2023-12-18     62.982517\n",
       "2023-12-19     62.897327\n",
       "2023-12-20     63.214344\n",
       "2023-12-21     64.936142\n",
       "2023-12-22     67.635742\n",
       "2023-12-23     70.713799\n",
       "2023-12-24     71.208633\n",
       "2023-12-25     71.503044\n",
       "2023-12-26     69.728058\n",
       "2023-12-27     66.975769\n",
       "2023-12-28     65.860176\n",
       "2023-12-29     68.116287\n",
       "2023-12-30     71.885376\n",
       "2023-12-31     78.481628\n",
       "2024-01-01     83.694328\n",
       "2024-01-02     85.547241\n",
       "2024-01-03     90.343689\n",
       "2024-01-04     90.818649\n",
       "2024-01-05     93.426910\n",
       "2024-01-06     94.435844\n",
       "2024-01-07     90.914558\n",
       "2024-01-08     87.545715\n",
       "2024-01-09     86.693069\n",
       "2024-01-10     85.908752\n",
       "2024-01-11     89.038971\n",
       "2024-01-12     91.399719\n",
       "2024-01-13     92.728592\n",
       "2024-01-14     92.841324\n",
       "2024-01-15     97.864197\n",
       "2024-01-16     97.514549\n",
       "2024-01-17     95.622238\n",
       "2024-01-18     93.904755\n",
       "2024-01-19     96.943695\n",
       "2024-01-20    100.323753\n",
       "2024-01-21     97.645775\n",
       "2024-01-22     94.387726\n",
       "2024-01-23     92.789429\n",
       "2024-01-24     93.760445\n",
       "2024-01-25     94.487450\n",
       "2024-01-26     95.450752\n",
       "2024-01-27     93.024963\n",
       "2024-01-28     91.755241\n",
       "2024-01-29     96.315460\n",
       "2024-01-30     98.155540\n",
       "2024-01-31     98.446419\n",
       "2024-02-01     95.910789\n",
       "2024-02-02     94.962318\n",
       "2024-02-03     93.810791\n",
       "2024-02-04     94.573174\n",
       "2024-02-05     97.829933\n",
       "2024-02-06     98.616287\n",
       "2024-02-07    104.701141\n",
       "2024-02-08    114.063591\n",
       "2024-02-09    118.536255\n",
       "2024-02-10    117.751129\n",
       "2024-02-11    122.040359\n",
       "2024-02-12    125.387932\n",
       "2024-02-13    129.443008\n",
       "2024-02-14    130.032593\n",
       "2024-02-15    133.956757\n",
       "2024-02-16    130.167114\n",
       "2024-02-17    126.664360\n",
       "2024-02-18    130.780457\n",
       "2024-02-19    133.642181\n",
       "2024-02-20    132.281174\n",
       "2024-02-21    130.530685\n",
       "2024-02-22    131.752563\n",
       "2024-02-23    133.721207\n",
       "2024-02-24    136.446136\n",
       "2024-02-25    139.082764\n",
       "2024-02-26    130.462952\n",
       "2024-02-27    128.798615\n",
       "2024-02-28    129.018875\n",
       "2024-02-29    131.700348\n",
       "2024-03-01    132.447983\n",
       "2024-03-02    132.102112\n",
       "2024-03-03    134.435181\n",
       "2024-03-04    131.987061\n",
       "2024-03-05    130.849411\n",
       "2024-03-06    126.294052\n",
       "2024-03-07    130.228851\n",
       "2024-03-08    129.601349\n",
       "2024-03-09    122.468475\n",
       "2024-03-10    121.248276\n",
       "2024-03-11    124.306877\n",
       "2024-03-12    123.180168\n",
       "2024-03-13    123.874733\n",
       "2024-03-14    124.275467\n",
       "2024-03-15    127.407402\n",
       "2024-03-16    125.240501\n",
       "2024-03-17    123.675476\n",
       "2024-03-18    118.372581\n",
       "2024-03-19    118.551979\n",
       "2024-03-20    121.718079\n",
       "2024-03-21    131.868790\n",
       "2024-03-22    135.355942\n",
       "2024-03-23    134.053131\n",
       "2024-03-24    132.032501\n",
       "2024-03-25    128.794189\n",
       "2024-03-26    123.618622\n",
       "2024-03-27    124.453789\n",
       "2024-03-28    127.336685\n",
       "2024-03-29    128.990540\n",
       "2024-03-30    141.548096\n",
       "2024-03-31    143.633194\n",
       "2024-04-01    149.272049\n",
       "2024-04-02    149.849670\n",
       "2024-04-03    147.437332\n",
       "2024-04-04    141.260208\n",
       "2024-04-05    141.441666\n",
       "2024-04-06    141.085037\n",
       "2024-04-07    147.738754\n",
       "2024-04-08    147.846756\n",
       "2024-04-09    144.126678\n",
       "Freq: D, dtype: float32"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.Series(data=transformed_future_predictions[:, 0], index=future_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d771dcc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
